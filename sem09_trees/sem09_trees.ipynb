{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение\n",
    "\n",
    "## Факультет математики НИУ ВШЭ\n",
    "\n",
    "### 2018-2019 учебный год\n",
    "\n",
    "Лектор: Илья Щуров\n",
    "\n",
    "Семинаристы: Евгения Ческидова, Евгений Ковалев\n",
    "\n",
    "Ассистенты: Константин Ваниев, Софья Дымченко"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня мы:\n",
    "\n",
    "- познакомимся с новым алгоритмом машинного обучения - решающим деревом\n",
    "\n",
    "- напишем код для разбиения вершины\n",
    "\n",
    "- <s>посадим дерево, вырастим сына, построим дом </s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающие деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='tree_example.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сами по себе решающие деревья используются в машинном обучении относительно редко, однако очень распространены методы, основанные на их композиции - ансамблях (Random Forest, XGBoost, LightGBM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Плюсы:\n",
    "\n",
    "- интерпретируемость\n",
    "- способность выделить самые важные признаки\n",
    "- отсутствие потребности в серьезной предобработке данных\n",
    "\n",
    "##### Минусы:\n",
    "\n",
    "- склонность к переобучению\n",
    "- неустойчивость - небольшие изменения в данных могут привести к сильному изменению в структуре дерева\n",
    "- эвристичность обучения - как оптимизировать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Линейная модель vs \"деревянная\" модель (основанная на решающих деревьях):\n",
    "\n",
    "- когда данные хорошо линейно разделимы, линейная модель лучше\n",
    "\n",
    "- когда данные плохо линейно разделимы (много сложных нелинейных зависимостей в данных), \"деревянная\" модель лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "data_x = np.random.normal(size=(100, 2))\n",
    "data_y = (data_x[:, 0] ** 2 + data_x[:, 1] ** 2) ** 0.5 # \n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "clf = DecisionTreeRegressor(random_state=13)\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "xx, yy = get_grid(data_x)\n",
    "\n",
    "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=100, cmap='spring', edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как будет выглядеть разделение плоскости в зависимости от максимальной глубины дерева и минимального числа объектов в листе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "for i, max_depth in enumerate([2, 4, None]):\n",
    "    for j, min_samples_leaf in enumerate([15, 5, 1]):\n",
    "        clf = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=13)\n",
    "        clf.fit(data_x, data_y)\n",
    "        xx, yy = get_grid(data_x)\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "        plt.subplot2grid((3, 3), (i, j))\n",
    "        plt.pcolormesh(xx, yy, predicted, cmap='spring')\n",
    "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='spring', edgecolor='k')\n",
    "        plt.title('max_depth=' + str(max_depth) + ' | min_samples_leaf=' + str(min_samples_leaf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неустойчивость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как будет меняться структура дерева, если брать для обучения разные 90%-ые подвыборки исходной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(3):\n",
    "    clf = DecisionTreeRegressor(random_state=13)\n",
    "\n",
    "    indecies = np.random.randint(data_x.shape[0], size=int(data_x.shape[0] * 0.9))\n",
    "    clf.fit(data_x[indecies], data_y[indecies])\n",
    "    xx, yy = get_grid(data_x)\n",
    "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    plt.subplot2grid((1, 3), (0, i))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap='winter')\n",
    "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='winter', edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(boston['target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(boston['data'], boston['target'], random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data_train, columns=boston['feature_names'])\n",
    "X_test = pd.DataFrame(data_test, columns=boston['feature_names'])\n",
    "X_train['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R_m$ - множество объектов в разбиваемой вершине, $i$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения.\n",
    "\n",
    "Качество:\n",
    "\n",
    "$$\n",
    "Q(R_m, i, t) = H(R_m) - \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) - \\frac{|R_r|}{|R_m|}H(R_r)\n",
    "$$\n",
    "\n",
    "$R_\\ell$ - множество объектов в левом поддереве, $R_r$ - множество объектов в правом поддереве.\n",
    "\n",
    "$H(R)$ - критерий информативности, с помощью которого можно оценить качество распределения целевой переменной среди объектов множества $R$.\n",
    "\n",
    "_Вопрос. Что мы хотим сделать с $H(R)$ - минимизировать или максимизировать? А $Q(R_m, i, t)$?_\n",
    "\n",
    "_Вопрос. Что можно использовать в качестве критерия информативности для регрессии? *А для классификации?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Реализуйте подсчет качества разбиения._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def H(R):\n",
    "    # your code here\n",
    "    return\n",
    "\n",
    "\n",
    "def split_node(R_m, feature, t):\n",
    "    # your code here\n",
    "    return R_l, R_r\n",
    "\n",
    "\n",
    "def quality(R_m, feature, t):\n",
    "    # your code here\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Переберите все возможные разбиения выборки по одному из признаков и постройте график качества разбиения в зависимости от значения порога._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Напишите функцию, находящую оптимальное разбиение данной вершины по данному признаку._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimal_split(R_m, feature):\n",
    "    # your code here\n",
    "    return t, Q_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Постройте график качества разбиения (в зависимости от количества объектов в левом поддереве) для каждого из признаков. Найдите признак, показывающий наилучшее качество. Какой это признак? Каков порог разбиения и значение качества? Постройте график качества разбиения для данного признака в зависимости от значения порога._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Изобразите разбиение визуально. Для этого постройте диаграмму рассеяния целевой переменной в зависимости от значения найденного признака. Далее изобразите вертикальную линию, соответствующую разбиению. Почему это разбиение лучшее? Как вы можете интерпретировать результат?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
