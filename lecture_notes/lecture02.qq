\chapter Напоминание: теория вероятностей и статистика
    \label chap:2:prob

\section Случайные величины
    \label sec:random-variables
    
\subsection Стандартное определение

Стадартное определение случайной величины выглядит так. Рассмотрим вероятностное
пространство $(\Omega, \mathcal F, \mathbb P)$, где $\Omega$ — пространство
элементарных исходов, $\mathcal F$ — множество событий (измеримых множеств) и
$\mathbb P$ — вероятностная мера (то есть $\mathbb P(\Omega)=1$). Случайной величиной
$X$ называется функция $X\colon \Omega \to \mathbb R$, измеримая относительно
$\mathcal F$ (то есть для любого интервала $(a, b)$, $X^{-1}((a, b))\in \mathcal
F$). 

Это определение хорошо своей математической строгостью, но на практике обычно
всё происходит наоборот — не случайная величина определяется по вероятностному
пространству, а вероятностное пространство строится по системе случайных
величин.

\subsection Случайная величина как мера на $\mathbb R$

В простейшем случае об этом можно думать так. Случайная величина $X$ задаёт
вероятностную меру на $\mathbb R$:
\equation \label eq:lec2:P_X
    \mathbb P_X(A)=\mathbb P(X^{-1}(A))=\mathbb P(X\in A),
где $A$ — некоторое множество из борелевской сигма-алгебры $\mathcal B^1$ на
$\mathbb R$ (то есть сигма-алгебры, порождённой интервалами). Если нас
интересует только случайная величина $X$, и никаких других случайных величин
нет, можно теперь забыть про исходное вероятностное пространство $(\Omega,
\mathcal F, \mathbb P)$ и думать про вероятностное пространство $(\mathbb R,
\mathcal B^1, \mathbb P_X)$. Иными словами, вместо того, чтобы генерировать
исход $\omega \in \Omega$ в соответствии с мерой $\mathbb P$, а потом
подставлять его в функцию $X$, чтобы получить число $X(\omega)$, мы можем сразу
выбрать случайное вещественное число в соответствии с мерой $\mathbb P_X$ и
считать его значением случайной величины $X$.

Кстати, мера $\mathbb P_X$ однозначно определяется \emph{функцией
распределения}:
\equation
    F_X(x)=\mathbb P_X((-\infty, x]) = \mathbb P(X \le x).

Если функция распределения дифференцируема, мера $\mathbb P_X$ является
абсолютно непрерывной относительно меры Лебега и у неё есть плотность:
\equation
    p_X(x)=F'(x)=\lim_{\Delta x \to 0}\frac{\mathbb P(X \in (x, x+\Delta
        x])}{\Delta x}.
Расписать определение производной здесь полезно, чтобы понять вероятностный
смысл плотности: это вероятность, что значение случайной величины попадёт в
маленький промежуток, делённая на длину этого промежутка.

По плотности можно восстановить меру $\mathbb P_X$ с помощью интегрирования:
\equation \label eq:lec2:int_A_p_X
    \mathbb P_X(A)=\int_A p_X(x) dx.

Если нас интересует только одна случайная величина и больше ничего, достаточно
задать её функцию распределения, а если случайная величина абсолютно непрерывна,
то достаточно задать плотность, после этого можно исследовать всевозможные
свойства этой случайной величины.

\subsection Система случайных величин

Если же нас интересует не одна случайная величина, а несколько, построение
немножко усложняется: задать распределение каждой случайной величины
недостаточно.

\example
    Пусть $X$ — случайная величина с равномерным распределением на отрезке $[0,
    1]$ (то есть $p_X(x)=\mathbb I_{[0, 1]}(x)$, где $\mathbb I$ —
    функция-индикатор).  Пусть $Y=1-X$, а $Z$ — ещё одна случайная величина
    величина с равномерным распределением на отрезке $[0, 1]$, независимая от
    $X$. (Можно думать об этом так: у нас есть программа, генерирующая случайные
    числа от 0 до 1. Значения $X$ и $Z$ получаются независимыми запусками этой
    программы, а значение $Y$ вычисляется по $X$.) Тогда все три случайные
    величины по отдельности имеют одно и то же распределение — равномерное на
    отрезке. Но при этом пара случайных величин $(X, Y)$ — это
    совсем не то же самое, что пара случайных величин $(X, Z)$.


Рассмотрим наиболее простой случай: пусть у нас есть две случайные величины $X$ и $Y$, заданные на одном и том же
вероятностном пространстве. Рассмотрим их \emph{совместное распределение}, то
есть меру на $\mathbb R\times \mathbb R$, заданную следующим образом:
\equation
    \mathbb P_{X, Y}(A \times B)=\mathbb P((X \in A) \cap (Y \in B))
для любых борелевских множеств (на прямой) $A$ и $B$.

Меру $\mathbb P_{X, Y}$ можно задавать функцией совместного распределения:
\equation
    F_{X, Y}(x, y)=\mathbb P((X \le x) \cap (Y \le y))
Если $\mathbb P_{X, Y}$ абсолютно непрерывна относительно меры Лебега,
существует совместная плотность
\equation
    p_{X, Y}(x, y)=\lim_{\substack{\Delta x \to 0\\\\\\Delta y \to 0}}
    \frac{\mathbb P((X \in (x, x+\Delta x]\cap (Y \in (y, y + \Delta y])}{\Delta
        x \Delta y}.
\question
    Как выразить совместную плотность через функцию совместного распределения?

Таким образом, если нас интересует пара случайных величин, можно рассматривать
вероятностное пространство $(\mathbb R^2, \mathcal B^2, \mathbb P_{X, Y})$.

\question
    Пусть пара случайных величин задаётся совместной плотностью $p_{X, Y}(x,
    y)$. Допустим, мы хотим «забыть» про $Y$ и узнать, как распределена величина
    $X$, то есть найти $\mathbb P_{X}$ (в соответствии с определением в
    \ref{eq:lec2:P_X}). Как это сделать?
    \quiz
        \choice Узнать ответ
            \correct
            \comment
                Нужно рассмотреть \emph{маргинальную плотность}:
                \eq
                    p_{X}(x)=\int_{\mathbb R}p_{X, Y}(x, y) dy,
                затем воспользоваться \ref{eq:lec2:int_A_p_X}

\section Условные распределения
Напомним определение условной вероятности. 

\definition
    Пусть $U$ и $V$ — некоторые события.
    Условной вероятностью $U$ при условии $V$ называется
    \equation \label lec2:eq:indep
        \mathbb P(U \mid V) = \frac{\mathbb P(U \cap V)}{\mathbb P(V)}.
\definition
    События $U$ и $V$ называются \emph{независимыми}, если $P(U\mid V)=P(U)$.
    Это условие эквивалентно $P(V\mid U)=P(V)$ и $P(U \cap V)=P(U)P(V)$.
\definition
    Две случайные величины $X$ и $Y$ называются \emph{независимыми}, если для
    любых двух борелевских множеств $A$ и $B$, 
    \eq
        \mathbb P((X\in A)\cap (Y\in B))=
        \mathbb P(X \in A) \cdot \mathbb P(Y \in B).
Это определение согласуется с определением независимости событий, приведённом
выше.

Кстати, если случайных величин больше двух, можно ввести определение
\emph{независимости в совокупности}.

\definition
    Случайные величины $X_1, \ldots, X_n$ называются \emph{независимыми в
    совокупности}, если для любых борелевских множеств $A_1, \ldots, A_n$,
    \eq
        \mathbb P\left(\bigcap_{i=1}^n (X_i \in A_i)\right)=
        \prod_{i=1}^n \mathbb P(X_i \in A_i)
    

Вернёмся к случаю, когда у нас есть пара случайных величин $X$ и $Y$ и мы хотим
определить распределение случайной величины $X$ при условии, что значение $Y$
равно какому-то конкретному числу $y_0$, то есть задать такую штуку: 
\eq
    \mathbb P(X \in A\mid Y = y_0).

Если $Y$ — дискретная случайня величина, можно применить формулу
\ref{lec2:eq:indep}, но если распределение $Y$ не является дискретным,
могут вознкнуть проблемы, потому что вероятность $\mathbb P(Y=y_0)$ в этом
случае может быть нулевой. Но если у нас есть совместная плотность, то эту
трудность можно обойти.

Определим \emph{условную плотность} следующим образом:

\equation \label eq:lec2:cond_dens
    p_{X\mid Y}(x\mid y)=\frac{p_{X, Y}(x, y)}{p_{Y}(y)}.

Тогда условное распределение задаётся с помощью интегрирования:
\eq
    \mathbb P(X \in A\mid Y = y_0) = \int_A p_{X\mid Y}(x\mid y_0)dx.

Вообще, условное распределение — это хитрая штука; если есть просто какая-то
абстрактная вероятностная мера, соответствующая условная мера относительна
подмножества меры нуль может не быть корректно определена, см.  \href[парадокс
Бореля — Колмогорова][https://en.wikipedia.org/wiki/Borel–Kolmogorov_paradox].
Но мы с такими проблемами сталкиваться ну будем, потому что нас интересуют не
произвольные меры, а заданные случайными величинами, причём случайные величины
либо дискретные, либо абсолютно непрерывные.

\subsection Пример: линейная модель

Напомним определение \emph{нормального распределения}. Случайная величина $W$
распределена по нормальному закону с матожиданием $\mu$ и дисперсией $\sigma^2$,
если её плотность задаётся следующим образом:
\eq
    p_W(w)=\frac{1}{\sqrt{2\pi
        \sigma^2}}\exp\left[-\frac{(w-\mu)^2}{2\sigma^2}\right].

Пишут:
\eq
    w \sim \mathcal N(\mu, \sigma^2)

Распределение $\mathcal N(0, 1)$ называется \emph{стандартным нормальным}.

\example
    Рассмотрим пару случайных величин $(X, Y)$, заданную следующим образом.
    Величина $X$ распределена по стандартному нормальному закону:
    \eq
        X \sim \mathcal N(0, 1).
    Зафиксируем некоторое число $\eps_0>0$ и рассмотрим вспомогательную
    случайную величину $\eps \sim \mathcal N(0, \eps_0^2)$, независимую от $X$.

    Положим
    \eq
        Y = \frac{X}{2} + \eps.

    Найдём совместную плотность $p_{X, Y}$. Для этого воспользуемся уравнением
    \ref{eq:lec2:cond_dens}, поменяем в нём местами $X$ и $Y$ и выразим $p_{X,
    Y}$. Имеем:

    \eq
        p_{X, Y}(x, y) = p_X(x) p_{Y|X}(y|x).

    По определению стандартной случайной величины,
    \eq
        p_X(x)=\frac{1}{\sqrt{2\pi}}\exp\left[-\frac{x^2}{2}\right]
    Пусть $X=x_0$. В этом случае $Y=\frac{x_0}{2}+\eps$. Функция плотности для
    $Y$ получается из функции плотности для $\eps$ сдвигом на константу
    $\frac{x_0}{2}$. То есть $Y$ имеет нормальное распределение с матожиданием
    $\frac{x_0}{2}$ и дисперсией $\eps_0^2$. Это часто записывают так:
    \eq
        Y\mid X=x_0 \sim \mathcal N\left(\frac{x_0}{2}, \eps_0^2\right)
    Таким образом,
    \eq
        p_{Y\mid X}(y\mid x)=\frac{1}{\sqrt{2\pi \eps_0^2}}
            \exp\left[-\frac{(y-\frac{x}{2})^2}{2\eps_0^2}\right].
    Имеем:
    \eq
        p_{X, Y}(x, y)=\frac{1}{2\pi
            \eps_0}\exp\left[-\frac{1}{2}\left(x^2+\frac{(2y-x)^2}{8\eps_0^2}\right)\right]
    \question
        Как выглядит график и линии уровня совместной плотности? Как они зависят
        от $\eps_0$? Что поисходит при $\eps_0 \to 0$?

\section Условное матожидание
\definition
    \emph{Математическим ожиданием (средним)} случайной величины $X$ называется её интеграл по
    всему вероятностному пространству:
    \equation
        \mathbb E[X]=\int_\Omega X(\omega) d\mathbb P(\omega).
    На практике обычно используется такая форма:
    \equation
        \mathbb E[X]=\int_{\mathbb R} x\, d\mathbb P_{X}(x).
    Если случайная величина $X$ имеет плотность, этот интеграл записывается в
    виде
    \equation
        \mathbb E[X] = \int_{\mathbb R} x\,p_{X}(x) dx.

Пусть теперь есть две случайные величины, $X$ и $Y$, и у них есть совместная
плотность $p_{X, Y}(x, y)$.

Рассмотрим такую функцию от числа $y_0$:
\eq
    H(y_0)=\int_{\mathbb R} x\, p_{X\mid Y}(x\mid y_0) dx
Для каждого $y_0$, величина $H(y_0)$ — это какое-то число (не случайная
величина, а честное число). Она обычно обозначается так:
\eq
    H(y_0)=:\mathbb E[X\mid Y=y_0]
Рассмотрим теперь $H(Y)$. Если взять случайную величину и подставить её в
какую-то обычную функцию, получится новая случайная величина. В данном случае
$Y$ — случайная величина, и $H(Y)$ — новая случайная величина, которая
называется \emph{условным матожиданием}.  Обозначается
\eq
    \mathbb E[X\mid Y].

\section Элементы статистики
\subsection Выборки

Пусть есть случайная величина $X$, распределение которой нам в точности
неизвестно, и пусть у нас есть \emph{выборка} из этой случайной величины, то
есть последовательность чисел $x_1, \ldots, x_n$, полученных как независимые
реализации случайной величины $X$. Мы хотим, глядя на выборку, что-то сказать
про распределение $X$.

\example 
    Допустим, у нас есть монетка, которая падает орлом с вероятностью $p$ и
    решкой с вероятностью $(1-p)$. Подкинем эту монетку $n$ раз и будем каждый
    раз при выпадении орла записывать число $1$, а при выпадении решки число
    $0$. Получим последовательность из $n$ нулей и единиц. Эта
    последовательность является выборкой из случайной величины $X$, имеющей
    распределение $\mathbb P(X = 1)=p$, $\mathbb P(X=1)=1-p$.

\example
     Рассмотрим ту же монетку, что и в предыдущем примере, но свяжем с ней
     другую случайную величины. Пусть $X$ — число выпавших орлов при пяти
     подбрасываниях нашей монетки. Сделаем $n$ серий по пять подбрасываний и
     после каждой серии запишем, сколько орлов в ней выпало. Снова получим $n$
     чисел $x_1, \ldots, x_n$, но теперь каждый $x_i$ — это не ноль или единица,
     а целое число от нуля до пяти. Они являются независимыми реализациями
     случайной величины $X$, имеющей биномиальное распределение $Bin(5, p)$:
     $\mathbb P(X=k)=C_5^k p^k (1-p)^{5-k}$.

\example
    Вместо подбрасывания монетки можно считать, что значения $X$ генерирует
    компьютер с помощью специальной программы — генератора случайных чисел.
    Тогда $x_1, \ldots, x_n$ — результаты независимого запуска этой программы.

Про числа $x_1, \ldots, x_n$ можно ещё думать так. Пусть у нас есть случайные
величины $X_1, \ldots, X_n$, независимые в совокупности, и распределённые так
же, как $X$. Тогда весь набор $(x_1, \ldots, x_n)$ является одной реализацией
многомерной случайной величины $(X_1, \ldots, X_n)$. Часто в рассуждениях не
делают разницу между случайными величинами и их конкретными реализациями: при
теоретическом анализе, выборка — это многомерная случайная величина, при
практических применениях — это конкретный набор данных, который нам нужно
исследовать, про который мы верим, что он получен как реализация соответствующей
случайной величины.

\subsection Статистические оценки и их свойства
\subsubsection Выборочное среднее

Вернёмся к примеру с монеткой. Пусть $X$ — случайная величина, равная 1 при
выпадении орла и 0 при выпадении решки, $p$ — вероятность выпадения орла. Её
матожидание равно $p$. Пусть мы получили такую выборку из $X$: 

\eq
    1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1. 
Что мы можем сказать про $p$?

Рассмотрим функцию $\Ave$ от выборки, называемую \emph{выборочным средним}. Это просто среднее арифметическое: 
\eq
    \Ave(x_1, \ldots, x_n)=\frac{x_1 + \ldots + x_n}{n}

Согласно закону больших чисел,
\equation \label eq:02:consistency_ave
    \Ave(x_1, \ldots, x_n) \to \mathbb EX,\quad n \to \infty
по вероятности. (Здесь мы снова считаем, что $x_1, \ldots, x_n$ — это случайные
величины.) Это значит, что выборочное среднее можно использовать для оценки
матожидания случайной величины, из которой взята выборка. В нашем примере, чтобы
оценить $p$ нужно посчитать, какую долю составляют единицы в нашей выборке.

Соотношение \ref{eq:02:consistency_ave} является частным случаем утверждения о
состоятельности оценки. Общее определение выглядит так.

\definition
    Пусть $x_1, \ldots, x_n$ — выборка из случайной величины $X_{\theta}$,
    распределение которой зависит от параметра $\theta$. Говорят, что функция
    $\hat \theta(x_1, \ldots, x_n)$ является \emph{состоятельной оценкой} для
    $\theta$, если для любого фиксированного значения $\theta$,
    \eq
        \hat \theta(x_1, \ldots, x_n) \to \theta
    по вероятности при $n \to \infty$.

Таким образом, соотношение \ref{eq:02:consistency_ave} утверждает, что $\Ave$
является состоятельной оценкой для матожидания $\mathbb EX$.

Грубо говоря, состоятельность означает, что чем больше размер выборки, тем лучше
наша оценка приближает истинное значение параметра распределения.

Помимо состоятельности нас будет интересовать ещё одно свойство:
\emph{несмещённость}.  Напомним, что мы считаем $x_1, \ldots, x_n$ случайными
величинами. Зафиксируем $n$ и рассмотрим матожидание $\mathbb E \Ave(x_1,
\ldots, x_n)$:
\eq
    \mathbb E \Ave(x_1, \ldots, x_n)=E\frac{x_1 + \ldots +
        x_n}{n}=\frac{1}{n}(\mathbb E[x_1] + \ldots + \mathbb
    E[x_n])=\frac{1}{n}(\mathbb E[X] + \ldots + \mathbb E[X])= \mathbb E[X],
где в последней сумме $n$ одинаковых слагаемых.

Иными словами, это означает следующее. Зафиксируем некоторое $n$ и сгенерируем
много-много выборок длины $n$. Для каждой посчитаем выборочное среднее. Затем
посчитаем среднее этих средних. Полученное среднее будет близко к
истинному матожиданию $\mathbb EX$.

Общее определение звучит так:
\definition
    Функция от выборки $\hat \theta$ называется \emph{несмещённой оценкой} 
    для параметра $\theta$, если
    \eq
        \mathbb E \hat \theta(x_1, \ldots, x_n)=\theta.
\question
    В качестве оценки для матожидания можно использовать не только выборочное
    среднее. Пусть $\phi(x_1, \ldots, x_n) = x_1$. Являетя ли $\phi$
    состоятельной оценкой для матожидания? Несмещённой оценкой?

\question
    Рассмотрим функцию $\psi(x_1, \ldots, x_n) = \lambda_1 x_1 + \ldots +
    \lambda_n x_n$, где $\lambda_1, \ldots, \lambda_n$ — некоторые константы.
    При каких $\lambda_1, \ldots, \lambda_n$ эта функция будет несмещённой
    оценкой для матожидания?

\subsubsection Выборочная дисперсия
\definition
    \emph{Дисперсией} случайной величины $X$ называется матождание квадрата её
    отклонения от своего матожидания:
    \eq
        \mathbb D[X]:=\mathbb E[(X-\mathbb E[X])^2]
Оценивать по выборке можно не только матожидание, но и другие параметры
распределения — например, её дисперсию. Естественной оценкой для дисперсии
является выборочная дисперсия. Обозначим $\bar x = \Ave(x_1, \ldots, x_n)$.
\eq
    D(x_1, \ldots, x_n)=\frac{1}{n}((x_1 - \bar x)^2 + \ldots + (x_n - \bar x)^2).
Можно показать (и легко поверить), что выборочная дисперсия является
состоятельной оценкой для истинной дисперсии $\mathbb D[X]$. Однако, является ли
она несмещённой?

Оказывается, что нет.
\question
    Докажите это.

Оказывается, несмещнной оценкой для дисперсии является так называемая
\emph{исправленная} выборочная дисперсия, отличающаяся от обычной тем, что
деление происходит на $(n-1)$, а не на $n$:

\eq
    D_+(x_1, \ldots, x_n)=\frac{1}{n-1}((x_1 - \bar x)^2 + \ldots + (x_n - \bar x)^2).

\subsection Дисперсия оценок \label ssec:2:var
Пусть у нас есть две состоятельные несмещённые оценки для какого-нибудь
параметра (например, матожидания). Какая из этих оценок «лучше»? Та, которая
меньше ошибается, то есть меньше отклоняется от своего среднего значения
(которое, в силу предположения несмещённости, равно истинному значению
параметра), то есть та, у которой меньше дисперсия.

Найдём дисперсию $\Ave$. Для этого напомним свойства дисперсии:

\align
    \item \mathbb D[cX]&=c^2 \mathbb D[X],
    \item \mathbb D[X+Y]& = \mathbb D[X] + \mathbb D[Y],
где $c$ — константа (неслучайная величина), $X$ и $Y$ независимы.

Итак, имеем:

\align\nonumber
    \item \mathbb D[\Ave(x_1, \ldots, x_n)]=\mathbb D\left[\frac{x_1 + \ldots + x_n}{n}\right] =
    \item = \frac{1}{n^2}(\mathbb D[x_1] + \ldots + \mathbb D[x_n])=\frac{\mathbb
            D[X]}{n}.

То есть дисперсия оценки среднего уменьшается линейно с ростом размера выборки $n$.

\question
    Рассмотрим функцию $\phi(x_1, \ldots, x_n)=\lambda_1 x_1 + \ldots +
    \lambda_n x_n$. При каких $\lambda_1, \ldots, \lambda_n$ эта функция
    является несмещённой оценкой для матожидания, имеющей наименьшую дисперсию?
